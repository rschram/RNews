# app/app.R
library(shiny)
library(visNetwork)
library(tidyverse)
library(igraph)
library(Matrix)
library(text2vec)
library(here)

# ==============================================================================
# 1. ROBUST PATHS (Fixes the "Missing File" Warning)
# ==============================================================================
source(here::here("config.R"))
source(here::here("R", "text_utils.R"))    # Highlighter
source(here::here("R", "graph_utils.R"))   # Graph Filter

# ==============================================================================
# 2. LOAD DATA (SMART LOADER)
# ==============================================================================

# A. LOAD MODEL (The DTM)
model <- readRDS(here::here("data", "app_ready", "model_current.rds"))

# B. LOAD VECTORS (Handle raw 'vectors_obj')
# We look for the file generated by your QMD script
vec_path <- here::here("data", "processed", "vectors.rds") 
if (!file.exists(vec_path)) vec_path <- here::here("data", "vectors.rds") # Fallback

if (file.exists(vec_path)) {
  raw_vecs <- readRDS(vec_path)
  
  # CASE 1: It's the "vectors_obj" LIST (Word Vectors + Metadata)
  if (is.list(raw_vecs) && !is.data.frame(raw_vecs) && "vectors" %in% names(raw_vecs)) {
    message(">> Found Word Vector Object. Calculating Document Vectors on the fly...")
    
    # 1. Extract Word Vectors
    word_matrix <- raw_vecs$vectors
    
    # 2. Extract Metadata (if you said it's in there!)
    if (!is.null(raw_vecs$meta)) {
      model$meta <- raw_vecs$meta
      message(">> Metadata extracted from vector object.")
    }
    
    # 3. Convert Word Vectors -> Document Vectors
    # Math: Doc_Vec = DTM (Docs x Words) * Word_Vecs (Words x Dim)
    common_vocab <- intersect(colnames(model$dtm), rownames(word_matrix))
    
    if (length(common_vocab) > 0) {
      dtm_aligned <- model$dtm[, common_vocab]
      wv_aligned  <- word_matrix[common_vocab, ]
      
      # The Magic Calculation
      vectors <- as.matrix(dtm_aligned %*% wv_aligned)
      message(sprintf(">> Calculated %d Document Vectors.", nrow(vectors)))
    } else {
      warning("No overlapping vocabulary between DTM and Word Vectors!")
      vectors <- NULL
    }
    
    # CASE 2: It's already a MATRIX (Document Vectors)
  } else if (is.matrix(raw_vecs) || is.data.frame(raw_vecs)) {
    vectors <- as.matrix(raw_vecs)
    message(">> Loaded pre-calculated Document Vectors.")
    
  } else {
    warning("vectors.rds loaded but format is unrecognized.")
    vectors <- NULL
  }
} else {
  warning("vectors.rds NOT FOUND. Falling back to DTM Word Counts.")
  vectors <- NULL
}

# C. LOAD METADATA (Fallback if not found in vectors)
if (is.null(model$meta)) {
  corpus_path <- here::here("data", "corpus.rds")
  if (file.exists(corpus_path)) {
    corpus_obj <- readRDS(corpus_path)
    if (is.data.frame(corpus_obj)) model$meta <- corpus_obj
    else if (!is.null(corpus_obj$meta)) model$meta <- corpus_obj$meta
  }
}
# ==============================================================================
# 3. PRE-CALCULATION (Layout & Metadata)
# ==============================================================================

if (igraph::vcount(model$graph) > 0) {
  message(">> Pre-calculating layout & attributes...")
  
  # A. Layout (DrL for speed)
  # Only calc if x/y don't exist yet
  if(is.null(igraph::V(model$graph)$x)) {
    coords <- igraph::layout_with_drl(model$graph, options=list(simmer.attraction=0))
    igraph::V(model$graph)$x <- coords[,1] * 100 
    igraph::V(model$graph)$y <- coords[,2] * 100
  }
  
  # B. Titles (Hover Tooltips)
  # This fixes the "doc_id" hover issue
  if (!is.null(model$meta)) {
    # Match graph IDs to metadata IDs
    # distinct() ensures we don't get duplicates if metadata is messy
    meta_distinct <- model$meta %>% dplyr::distinct(doc_id, .keep_all = TRUE)
    indices <- match(igraph::V(model$graph)$name, meta_distinct$doc_id)
    
    # Assign headlines
    titles <- meta_distinct$headline[indices]
    # Fill NAs with IDs
    titles[is.na(titles)] <- igraph::V(model$graph)$name[is.na(titles)]
    igraph::V(model$graph)$title <- titles
  } else {
    igraph::V(model$graph)$title <- igraph::V(model$graph)$name
  }
}

# ==============================================================================
# UI
# ==============================================================================
ui <- fluidPage(
  tags$head(tags$style(fruit_salad_css)),
  
  titlePanel("Discourse graph workbench"),
  
  sidebarLayout(
    sidebarPanel(
      width = 3,
      # --- 1. SEARCH & FILTER ---
      h4("1. Search & Filter"),
      textInput("search_term", NULL, placeholder = "Search terms..."),
      checkboxGroupInput("highlights", "Highlight Layers:",
                         choices = c("Search Terms" = "query", "Bursty Words" = "bursty", "Shared (Edge)" = "shared"),
                         selected = c("bursty", "shared")),
      hr(),
      
      # --- 2. GRAPH METRICS (NEW) ---
      h4("2. Graph State"),
      uiOutput("live_metrics"), # <--- LIVE STATS HERE
      hr(),
      
      # --- 3. REBUILD CONTROLS ---
      h4("3. Reconstruction"),
      sliderInput("burst_percentile", "Vocab Specificity:", 
                  min = 0, max = 0.95, value = 0, step = 0.05, post = "cut"),
      sliderInput("threshold", "Link Strength:", 0.1, 0.9, 0.5, step = 0.05),
      actionButton("update_graph", "Re-Build Graph", icon = icon("sync"), 
                   class = "btn-primary btn-block")
    ),
    
    mainPanel(
      width = 9,
      # SPLIT VIEW: GRAPH ON TOP, WORKBENCH BELOW
      
      # Top: The Graph
      div(style = "border-bottom: 2px solid #ddd; padding-bottom: 20px; margin-bottom: 20px;",
          visNetworkOutput("net_plot", height = "500px")
      ),
      
      # Bottom: The Workbench (Tabset)
      tabsetPanel(id = "workbench_tabs",
                  
                  # TAB A: SELECTION TABLE (New)
                  tabPanel("Selection Workbench", icon = icon("list"),
                           br(),
                           h4("Selected Documents & Edge Composition"),
                           p("Select 2+ nodes to see shared terms."),
                           tableOutput("selection_table") # <--- THE NEW TABLE
                  ),
                  
                  # TAB B: DOC VIEWER (Original)
                  tabPanel("Document Reader", icon = icon("file-alt"),
                           br(),
                           uiOutput("inspector_header"),
                           htmlOutput("doc_viewer")
                  ),
                  
                  # TAB C: VOCAB PLOT (Moved down)
                  tabPanel("Vocabulary Plot", icon = icon("chart-bar"),
                           plotlyOutput("vocab_plot", height = "500px")
                  )
      )
    )
  )
)

# ==============================================================================
# SERVER
# ==============================================================================
server <- function(input, output, session) {
  
  # --- A. DATA REACTIVES ---
  current_graph <- eventReactive(input$update_graph, {
    
    withProgress(message = "Re-building graph...", detail = "Calculating Similarity...", {
      
      # (Vocab filtering logic can stay, though it only affects DTM mode now)
      cutoff_rank <- input$burst_percentile
      n_terms <- nrow(model$stats)
      keep_n <- ceiling(n_terms * (1 - cutoff_rank))
      vocab_terms <- model$stats %>% arrange(Residual) %>% head(keep_n) %>% pull(Term)
      
      # --- FIX 3: PASS VECTORS ---
      # This ensures the rebuild matches the offline Embedding analysis
      g_new <- build_dynamic_graph(model$dtm, 
                                   vectors = vectors, # <--- PASS VECTORS HERE
                                   threshold = input$threshold, 
                                   vocab_terms = vocab_terms)
      
      incProgress(0.6, detail = "Calculating Layout...")
      
      # Calculate Layout
      coords <- igraph::layout_with_drl(g_new, options=list(simmer.attraction=0))
      igraph::V(g_new)$x <- coords[,1] * 100
      igraph::V(g_new)$y <- coords[,2] * 100
      
      # --- FIX 4: PRESERVE TITLES ---
      # Re-attach titles so tooltips don't vanish on rebuild
      if (!is.null(model$meta)) {
        indices <- match(igraph::V(g_new)$name, model$meta$doc_id)
        titles <- model$meta$headline[indices]
        titles[is.na(titles)] <- igraph::V(g_new)$name[is.na(titles)]
        igraph::V(g_new)$title <- titles
      }
      
      return(g_new)
    })
  }, ignoreNULL = FALSE)
  
  final_graph <- reactive({
    # If the user hasn't clicked update yet, use the static model
    if (input$update_graph == 0) {
      return(model$graph)
    } else {
      return(current_graph())
    }
  })
  
  
  # --- B. SEARCH LOGIC ---
  matched_docs <- reactive({
    req(input$search_term)
    term <- tolower(input$search_term)
    if (term %in% colnames(model$dtm)) {
      indices <- which(model$dtm[, term] > 0)
      return(rownames(model$dtm)[indices])
    }
    return(NULL)
  })
  
  
  # --- C. GRAPH RENDER ---
  output$net_plot <- renderVisNetwork({
    g <- final_graph()
    target_ids <- if(isTruthy(input$search_term)) matched_docs() else NULL
    
    # --- FIX 2: FAST EDGE FILTERING ---
    # We filter edges visually based on the slider. 
    # This prevents rendering 50,000 weak edges on startup.
    # Note: We can only filter UP (higher threshold). To go lower than 
    # the base model (0.3), the user must click "Re-Build".
    
    current_threshold <- input$threshold
    
    # Prune edges below threshold (Fast visual filter)
    # delete.edges is very fast compared to re-layout
    g_vis <- igraph::subgraph.edges(g, igraph::E(g)[weight >= current_threshold], delete.vertices = FALSE)
    
    vis_data <- prepare_visual_graph(g_vis, target_ids)
    
    visNetwork(vis_data$nodes, vis_data$edges) %>%
      visEdges(smooth = FALSE, width = 0.5, color = list(color = "rgba(150,150,150, 0.4)", highlight = "black")) %>%
      
      # Node Styling (Large & Blue)
      visNodes(size = 30, shape = "dot", 
               color = list(background = "#97C2FC", border = "#2B7CE9", highlight = "#FF4040")) %>%
      
      visPhysics(enabled = FALSE) %>% 
      visInteraction(multiselect = TRUE, navigationButtons = TRUE, zoomView = TRUE, dragView = TRUE) %>%
      visEvents(select = "function(nodes) { Shiny.onInputChange('sel_node', nodes.nodes); }")
  })
  
  # --- LIVE METRICS RENDERER ---
  output$live_metrics <- renderUI({
    g <- final_graph()
    stats <- get_graph_metrics(g)
    
    if (is.null(stats)) return(helpText("No graph data."))
    
    tagList(
      div(style = "font-size: 13px;",
          strong("Similarity model:", format(model$model_name)), br(),
          strong("Nodes:"), format(stats$Nodes, big.mark=","), br(),
          strong("GCR:"), sprintf("%.1f%%", stats$GCR * 100), br(),
          strong("Modularity:"), sprintf("%.3f", stats$Modularity), br(),
          strong("Transitivity:"), sprintf("%.3f", stats$Transitivity), br(),
          strong("Assortativity:"), sprintf("%.3f", stats$Assortativity)
      )
    )
  })
  
  # --- D. VOCAB PLOT (With Lines) ---
  output$vocab_plot <- renderPlotly({
    req(model$stats)
    
    # 1. Calculate the Threshold (The Red Line)
    # Slider (0.0 - 0.95): Represents % of generic words to cut.
    # High Slider = Low Threshold (Only keeping very negative residuals/bursty words)
    threshold_val <- quantile(model$stats$Residual, 
                              probs = (1 - input$burst_percentile), 
                              na.rm = TRUE)
    
    # 2. Sort data for clean line drawing
    plot_data <- model$stats %>% arrange(Frequency)
    
    # 3. Build Plot
    plot_ly(plot_data, source = "vocab_plot") %>%
      
      # Layer A: The Dots (Words)
      add_markers(
        x = ~log10(Frequency), 
        y = ~Entropy, 
        text = ~paste("Term:", Term, 
                      "<br>Freq:", Frequency,
                      "<br>Entropy:", round(Entropy, 2),
                      "<br>Residual:", round(Residual, 2)),
        color = ~Residual, 
        colors = "RdBu", # Blue = Bursty (Low Residual), Red = Generic
        marker = list(opacity = 0.6, size = 6),
        name = "Words"
      ) %>%
      
      # Layer B: The "Null Model" (Gray Dashed Line)
      # This represents Residual = 0 (Expected Entropy)
      add_lines(
        x = ~log10(Frequency),
        y = ~Expected_Entropy,
        line = list(color = "rgba(100,100,100,0.5)", dash = "dash", width = 2),
        name = "Expected Entropy",
        hoverinfo = "none",
        inherit = FALSE
      ) %>%
      
      # Layer C: The "Ablation Cutoff" (Moving Red Line)
      # This represents the threshold. Points BELOW this line are "Kept" (Bursty).
      add_lines(
        x = ~log10(Frequency),
        y = ~ (Expected_Entropy + threshold_val),
        line = list(color = "red", dash = "dot", width = 1),
        name = paste("Cutoff:", round(threshold_val, 2)),
        hoverinfo = "none",
        inherit = FALSE
      ) %>%
      
      layout(
        title = "Word Entropy vs. Frequency",
        xaxis = list(title = "Log10 Frequency"), 
        yaxis = list(title = "Entropy"),
        showlegend = FALSE
      )
  })
  
  # --- SELECTION WORKBENCH TABLE ---
  output$selection_table <- renderTable({
    req(input$sel_node)
    sel <- input$sel_node
    
    # 1. Build Base Table for Each Selected Doc
    df <- data.frame(
      Doc_ID = sel,
      Headline = NA_character_,
      Bursty_Topic = NA_character_,
      Shared_Connectors = NA_character_,
      stringsAsFactors = FALSE
    )
    
    # 2. Populate Rows
    for(i in seq_along(sel)) {
      doc_id <- sel[i]
      
      # A. Headline (from metadata)
      if (!is.null(model$meta)) {
        match_idx <- match(doc_id, model$meta$doc_id)
        if (!is.na(match_idx)) {
          df$Headline[i] <- model$meta$headline[match_idx]
        } else {
          df$Headline[i] <- "(No Metadata)"
        }
      } else {
        df$Headline[i] <- "-"
      }
      
      # B. Bursty Words (Top 3 Distinctive)
      terms <- names(which(model$dtm[doc_id,] > 0))
      top_words <- model$stats %>% 
        filter(Term %in% terms) %>%
        arrange(Residual) %>% # Low Residual = Bursty
        head(3) %>%
        pull(Term) %>%
        paste(collapse = ", ")
      
      df$Bursty_Topic[i] <- top_words
      
      # C. Intersection Logic (Edge Decomposition)
      # If we have exactly 2 docs, show shared terms between them.
      if (length(sel) == 2) {
        other_id <- sel[setdiff(1:2, i)] # The "other" index
        
        # Get intersection
        vec_A <- model$dtm[doc_id, , drop=FALSE]
        vec_B <- model$dtm[other_id, , drop=FALSE]
        common <- intersect(names(which(vec_A[1,]>0)), names(which(vec_B[1,]>0)))
        
        # Sort common by rarity (Entropy)? Or just list them?
        # Let's list top 5 shared terms
        if(length(common) > 0) {
          shared_str <- paste(head(common, 5), collapse = ", ")
          df$Shared_Connectors[i] <- shared_str
        } else {
          df$Shared_Connectors[i] <- "(None)"
        }
      } else {
        df$Shared_Connectors[i] <- "-"
      }
    }
    
    return(df)
  }, striped = TRUE, hover = TRUE, width = "100%")
  
  observeEvent(input$sel_node, {
    # If user selects nodes, ensure the Workbench is visible
    # But don't force switch if they are reading text.
    # Actually, simpler: just let them switch manually, but default to Workbench?
    # Let's auto-switch to "Selection Workbench" only if they select > 1 node
    if (length(input$sel_node) > 1) {
      updateTabsetPanel(session, "workbench_tabs", selected = "Selection Workbench")
    }
  })
  
  # --- E. DOC INSPECTOR (REFACTORED) ---
  
  # 1. Determine "Focused" Document
  # This Logic: If multiple nodes are selected, use the Dropdown value. 
  # If the Dropdown is invalid (e.g., old selection), default to the first node.
  focused_doc_id <- reactive({
    req(input$sel_node)
    current_selection <- input$sel_node
    
    # Check if the user has selected a specific doc in the dropdown
    if (isTruthy(input$inspector_dropdown) && 
        input$inspector_dropdown %in% current_selection) {
      return(input$inspector_dropdown)
    }
    
    # Default: Return the first selected node
    return(current_selection[1])
  })
  
  # 2. Render the Header (Title vs Dropdown)
  output$inspector_header <- renderUI({
    req(input$sel_node)
    selection <- input$sel_node
    
    if (length(selection) > 1) {
      # Show a dropdown to switch between docs
      selectInput("inspector_dropdown", "Inspecting Document:", 
                  choices = selection, 
                  selected = focused_doc_id())
    } else {
      # Just show the title
      tagList(
        h4("Document Viewer"),
        h3(selection[1])
      )
    }
  })
  
  # 3. Render the Text (LIVE UPDATES)
  # This uses renderUI directly, so it reacts INSTANTLY to:
  # - focused_doc_id() changes (Switching docs)
  # - input$highlights changes (Toggling checkboxes)
  # - input$search_term changes (New search highlight)
  output$doc_viewer <- renderUI({
    req(focused_doc_id())
    
    doc_id <- focused_doc_id()
    
    # Safety Check: ID must exist in corpus
    if (!doc_id %in% names(model$full_text)) return(h4("Doc ID not found in text store."))
    
    # A. Get Content
    raw <- model$full_text[doc_id]
    doc_terms <- names(which(model$dtm[doc_id,] > 0))
    
    # B. Build Highlight Groups (Dynamic)
    groups <- list()
    
    # Layer 1: Search Query (Yellow)
    if ("query" %in% input$highlights && isTruthy(input$search_term)) {
      groups$query <- c(input$search_term)
    }
    
    # Layer 2: Bursty Words (Green)
    if ("bursty" %in% input$highlights) {
      top_bursty <- model$stats %>% 
        filter(Term %in% doc_terms) %>%
        arrange(Residual) %>% # Lowest Residual = Most Bursty
        head(20) %>%
        pull(Term)
      groups$bursty <- top_bursty
    }
    
    # Layer 3: Shared Terms (Blue)
    # Active if "shared" is checked AND we have a comparison (2+ nodes selected)
    if ("shared" %in% input$highlights && length(input$sel_node) > 1) {
      
      # 1. Identify the "Other" documents in the selection
      # (All selected nodes EXCEPT the one currently being viewed)
      current_doc <- doc_id
      other_docs <- setdiff(input$sel_node, current_doc)
      
      # 2. Calculate Intersection
      # We find terms present in the Current Doc AND at least one of the Other Docs.
      # (Standard "Edge" definition: Term exists in A and B)
      
      # Get vector for current doc
      vec_current <- model$dtm[current_doc, , drop=FALSE]
      terms_current <- names(which(vec_current[1, ] > 0))
      
      # Get vectors for other docs (summed or checked individually)
      # Fast way: Check against the first "Other" doc (primary comparison)
      # Robust way: Check against ALL others (union of others)
      
      if (length(other_docs) > 0) {
        # Let's compare against the first 'other' for clarity in pairwise mode
        # or aggregate all others if multi-select.
        
        # Strategy: Get terms in the 'other' selection
        vec_others <- model$dtm[other_docs, , drop=FALSE]
        # Using Matrix::colSums to find non-zero columns in the slice
        if (length(other_docs) > 1) {
          counts_others <- Matrix::colSums(vec_others)
          terms_others <- names(which(counts_others > 0))
        } else {
          terms_others <- names(which(vec_others[1, ] > 0))
        }
        
        # Intersection: Terms in Current AND Terms in Others
        common_terms <- intersect(terms_current, terms_others)
        
        # Add to highlight group
        if (length(common_terms) > 0) {
          groups$shared <- common_terms
        }
      }
    }
    
    # C. Highlight
    # Check if highlight function exists
    if(exists("highlight_fruit_salad")) {
      final_html <- highlight_fruit_salad(raw, groups)
      HTML(gsub("\n", "<br>", final_html))
    } else {
      HTML("<b style='color:red'>Error: Highlighter function not found.</b>")
    }
  })
}

shinyApp(ui, server)